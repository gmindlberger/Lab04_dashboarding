services:
  # jupyter notebook with pyspark integration
  jupyter-spark:
    # a custom container-image is built to add necessary packages
    build:
      context: ./src/container
      dockerfile: jupyter_pyspark.Dockerfile
    container_name: jupyter-spark
    hostname: jupyter-spark
    volumes:
      # if you are on linux with selinux (most distros these days)
      # you need to take care the volume is mounted with the defined selinux labels
      # https://docs.docker.com/engine/storage/bind-mounts/#configure-the-selinux-label
      - ./notebooks:/home/jovyan/notebooks:z 
    working_dir: /home/jovyan/notebooks
    ports:
      - "8888:8888" # notebook UI
      - "4040:4040" # UI for spark-jobs
    
  # https://min.io/
  # s3 compatible storage provided by minio
  minio:
    image: minio/minio:latest
    container_name: minio
    command: server /data --console-address ":9001"
    environment:
      - MINIO_ROOT_USER=admin
      - MINIO_ROOT_PASSWORD=password
    ports:
      - "9000:9000"   # MinIO API
      - "9001:9001"   # MinIO Console
    volumes:
      - ./minio-data:/data:z

  # https://kafka.apache.org/
  # Apache Kafka is an open-source distributed event streaming platform used by thousands of companies for high-performance 
  # data pipelines, streaming analytics, data integration, and mission-critical applications.
  kafka:
    image: bitnami/kafka:4.0
    container_name: kafka
    hostname: kafka
    environment:
       # KRaft settings
      - KAFKA_CFG_NODE_ID=0
      - KAFKA_CFG_PROCESS_ROLES=controller,broker
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka:9093
      # Listeners
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://:9092
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
    ports:
      - "9092:9092"

  
